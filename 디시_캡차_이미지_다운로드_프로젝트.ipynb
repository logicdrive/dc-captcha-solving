{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 관련 모듈 설치하기\n",
        "-----"
      ],
      "metadata": {
        "id": "6jPD2EEBPZQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "frn8yGRjPcMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 캡차 훈련 데이터를 수동으로 다운로드\n",
        "-----"
      ],
      "metadata": {
        "id": "zfdd1SpwPgYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "# HTTP 요청에 대한 통합된 인터페이스를 제공하기 위한 라이브러리\n",
        "class Request :\n",
        "  # 자연스러운 요청을 위한 기반 헤더\n",
        "  GLOBAL_HEADERS = {\"Accept\" : \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
        "                    \"Accept-Encoding\" : \"gzip, deflate, br\",\n",
        "                    \"Accept-Language\" : \"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
        "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"}\n",
        "\n",
        "  # HTTP GET 요청을 수행하고 응답을 받기 위해서\n",
        "  @staticmethod\n",
        "  def get(url, headers={}, cookies={}) :\n",
        "    headers.update(Request.GLOBAL_HEADERS)\n",
        "    return requests.get(url, headers=headers, cookies=cookies)\n",
        "  \n",
        "  # HTTP POST 요청을 수행해고 응답을 받기 위해서\n",
        "  @staticmethod\n",
        "  def post(url, headers={}, cookies={}, data={}) :\n",
        "    headers.update(Request.GLOBAL_HEADERS)\n",
        "    return requests.post(url, headers=headers, cookies=cookies, data=data)\n",
        "\n",
        "# DC 인사이드의 캡차 이미지를 얻기 위해서\n",
        "class Dcincide_Captcha_API :\n",
        "  def __init__(self) :\n",
        "    self.GALL_ID = \"birthrate\"\n",
        "    self.KCAPTCHA_TYPE = \"write\"\n",
        "    self.GALL_TYPE = \"M\"\n",
        "\n",
        "    self.SESSION_COOKIES = Request.get(f\"https://gall.dcinside.com/mgallery/board/write/?id={self.GALL_ID}\").cookies\n",
        "    self.SESSION_COOKIE_INFO = {\"PHPSESSID\":self.SESSION_COOKIES[\"PHPSESSID\"], \"ci_c\":self.SESSION_COOKIES[\"ci_c\"]}\n",
        "    self._init_Captcha_Session()\n",
        "  \n",
        "  # 새로운 캡차 이미지를 얻기 위해서 캡차 세션을 초기화시킴\n",
        "  def _init_Captcha_Session(self) :\n",
        "    SESSION_HTTP_HEADER = {\"Content-Type\":\"application/x-www-form-urlencoded; charset=UTF-8\", \"X-Requested-With\":\"XMLHttpRequest\"}\n",
        "    SESSION_DATAS = {\"ci_t\":self.SESSION_COOKIES[\"ci_c\"], \"gall_id\":self.GALL_ID, \"kcaptcha_type\":self.KCAPTCHA_TYPE, \"_GALLTYPE_\":self.GALL_TYPE}\n",
        "    Request.post(\"https://gall.dcinside.com/kcaptcha/session\", SESSION_HTTP_HEADER, self.SESSION_COOKIE_INFO, SESSION_DATAS)\n",
        "\n",
        "  # 생성된 캡차 세션에 존재하는 캡차 이미지를 PIL 형태로 얻기 위해서\n",
        "  def _captcha_Image(self) :\n",
        "    IMG_RES = Request.get(f\"https://gall.dcinside.com/kcaptcha/image/?gall_id={self.GALL_ID}&kcaptcha_type={self.KCAPTCHA_TYPE}\", {}, self.SESSION_COOKIE_INFO)\n",
        "    return Image.open(BytesIO(IMG_RES.content))\n",
        "\n",
        "  # 새로운 캡차 문자열 이미지를 얻기 위해서\n",
        "  def new_Captcha_Image(self) :\n",
        "    self._init_Captcha_Session()\n",
        "    return self._captcha_Image()\n",
        "  \n",
        "  # 이전과 정답이 동일하면서 형태만 다른 캡차 문자열 이미지를 얻기 위해서\n",
        "  def same_Captcha_Image(self) :\n",
        "    return self._captcha_Image()\n",
        "\n",
        "# 파일시스템 관련 조작을 위해서\n",
        "class File_System :\n",
        "  # 디렉토리가 없을 경우 생성시키기 위해서\n",
        "  @staticmethod\n",
        "  def make_Directory_If_Not_Exist(dir_path) :\n",
        "    if not os.path.exists(dir_path) : os.mkdir(dir_path)\n",
        "  \n",
        "  # 디렉토리 내부의 파일 개수를 반환받기 위해서\n",
        "  @staticmethod\n",
        "  def count_Num_Of_Files(dir_path) :\n",
        "    return len(os.listdir(dir_path))\n",
        "\n",
        "  # 특정 디렉토리를 .zip 형태로 압축시키기 위해서\n",
        "  @staticmethod\n",
        "  def compress_With_Zip(dir_path, zip_name) :\n",
        "    os.system(f\"zip -r {zip_name} {dir_path}\")\n",
        "\n",
        "  # 특정 디렉토리를 완전하게 삭제시키기 위해서\n",
        "  @staticmethod\n",
        "  def remove_Directory(dir_path) :\n",
        "    os.system(f\"rm -r {dir_path}\")\n",
        "\n",
        "# 자료형변환을 간편하게 수행하기 위한 라이브러리\n",
        "class Convert :\n",
        "  # 넘파이 배열을 PIL 이미지 형태로 변환시키기 위해서\n",
        "  @staticmethod\n",
        "  def numpy_Array_To_PIL_Image(numpy_array, color_channel=\"RGB\") :\n",
        "    return Image.fromarray(np.uint8(numpy_array)).convert(color_channel)"
      ],
      "metadata": {
        "id": "4N4TzGcCPkYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "IMAGE_DIRECTORY = \"./captchas\" # 캡차 이미지를 저장시킬 폴더\n",
        "GOAL_FILE_COUNT = 50 # 총 생성시킬 캡차 이미지 목표 개수\n",
        "\n",
        "File_System.make_Directory_If_Not_Exist(IMAGE_DIRECTORY)\n",
        "CAPTCHA_API = Dcincide_Captcha_API()\n",
        "LOADED_CAPTCHA_IMAGE = CAPTCHA_API.new_Captcha_Image()\n",
        "\n",
        "\n",
        "# 입력된 (캡차 이미지, 캡차 정답)을 특정 폴더에 저장시키기 위해서\n",
        "def save_Captcha_Image(captcha_image_array, captcha_answer) :\n",
        "  global CAPTCHA_API\n",
        "\n",
        "  while True :\n",
        "    try :\n",
        "      LOADED_CAPTCHA_IMAGE = CAPTCHA_API.new_Captcha_Image()\n",
        "      break\n",
        "    except :\n",
        "      time.sleep(3.0)\n",
        "      CAPTCHA_API = Dcincide_Captcha_API()\n",
        "\n",
        "  TOTAL_FILE_COUNT = File_System.count_Num_Of_Files(IMAGE_DIRECTORY)\n",
        "  if not captcha_answer :\n",
        "    return [LOADED_CAPTCHA_IMAGE, \"\", f\"Current captcha was passed ! (progress : {GOAL_FILE_COUNT}/{TOTAL_FILE_COUNT})\"]\n",
        "\n",
        "  IMAGE_FILE_PATH_TO_SAVE = f\"{IMAGE_DIRECTORY}/{captcha_answer}.jpg\"\n",
        "  Convert.numpy_Array_To_PIL_Image(captcha_image_array).save(IMAGE_FILE_PATH_TO_SAVE)\n",
        "  if TOTAL_FILE_COUNT+1 == GOAL_FILE_COUNT :\n",
        "    File_System.compress_With_Zip(IMAGE_DIRECTORY, \"./\" + IMAGE_DIRECTORY.split(\"/\")[-1] + \".zip\")\n",
        "    raise Exception(\"GOAL REACHED !\") \n",
        "\n",
        "  return [LOADED_CAPTCHA_IMAGE, \"\", f\"Inputed image was successfully saved in '{IMAGE_FILE_PATH_TO_SAVE}' (progress : {GOAL_FILE_COUNT}/{TOTAL_FILE_COUNT+1})\"]\n",
        "\n",
        "\n",
        "with gr.Blocks() as base_block :\n",
        "  CAPTCHA_IMAGE = gr.Image(value=LOADED_CAPTCHA_IMAGE, label=\"Captcha Image\")\n",
        "  CAPTCHA_ANSWER = gr.Textbox(label=\"Captcha Answer\")\n",
        "  RESULT_LOG = gr.Textbox(label=\"Save result\")\n",
        "\n",
        "  CAPTCHA_ANSWER.submit(fn=save_Captcha_Image, inputs=[CAPTCHA_IMAGE, CAPTCHA_ANSWER], outputs=[CAPTCHA_IMAGE, CAPTCHA_ANSWER, RESULT_LOG])\n",
        "\n",
        "base_block.launch(debug=True)"
      ],
      "metadata": {
        "id": "Va2GGrgbPohV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 신경망을 이용한 자동화된 캡차 이미지 훈련 데이터 다운로드\n",
        "-----"
      ],
      "metadata": {
        "id": "-gPNqJyuP2H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 관련 모듈들을 다운로드 받고, 주요 폴더를 미리 생성시키기 위해서\n",
        "!pip install pytorch-lightning torchmetrics"
      ],
      "metadata": {
        "id": "v1C_Wc_kQF9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정보 활용을 위한 압축해제\n",
        "!unzip ./Captcha_Train_Set_7000.zip\n",
        "!rm ./Captcha_Train_Set_7000.zip"
      ],
      "metadata": {
        "id": "YU_2yu-hQLcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "\n",
        "# 주어진 이미지 파일 경로의 이미지들을 이용해서 캡차 데이터셋을 생성시키기 위해서\n",
        "class Captcha_Dataset(Dataset) :\n",
        "  def __init__(self, image_dir_path) :\n",
        "    self.CORPUS = string.ascii_lowercase + string.digits\n",
        "    self.BOW = self.__make_BOW(self.CORPUS)\n",
        "    self.IMAGE_FILE_PATHS = glob.glob(image_dir_path + \"/*.jpg\")\n",
        "    self.COMPOSE = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.IMAGE_FILE_PATHS)\n",
        "\n",
        "  def __getitem__(self, i) :\n",
        "    IMAGE = self.COMPOSE(Image.open(self.IMAGE_FILE_PATHS[i]).convert(\"L\").convert(\"RGB\"))\n",
        "    DATA = np.array(IMAGE).astype(np.float32)\n",
        "    LABEL = np.array(self.__get_seq(self.__get_Label_From_Image_Path(self.IMAGE_FILE_PATHS[i])))\n",
        "    return DATA, LABEL\n",
        "\n",
        "  # 주어진 이미지 경로로부터 라벨을 추출시킨 결과를 반환하기 위해서\n",
        "  def __get_Label_From_Image_Path(self, image_path) :\n",
        "    return image_path.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "  # 주어진 문자열들을 BOW를 이용해서 정수 리스트로 변환시키기 위해서\n",
        "  def __get_seq(self, letters) :\n",
        "    return list(map(lambda letter : self.BOW[letter], letters))\n",
        "\n",
        "  # 주어진 문자열들에 대한 BOW를 생성시키고 반환하기 위해서\n",
        "  def __make_BOW(self, corpus) :\n",
        "    bow = {\"<pad>\":0}\n",
        "\n",
        "    for letter in corpus :\n",
        "      if letter not in bow :\n",
        "        bow[letter] = len(bow)\n",
        "\n",
        "    return bow"
      ],
      "metadata": {
        "id": "S9hIczz_QRQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습, 검증, 테스트 데이터셋 불러오고 관련 데이터 로더를 생성시키기 위해서\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "TRAIN_DATASET = Captcha_Dataset(\"./Captcha_Train_Set_7000/train_data\")\n",
        "VALID_DATASET = Captcha_Dataset(\"./Captcha_Train_Set_7000/valid_data\")\n",
        "TEST_DATASET = Captcha_Dataset(\"./Captcha_Train_Set_7000/test_data\")\n",
        "\n",
        "TRAIN_LOADER = DataLoader(TRAIN_DATASET, batch_size=8, shuffle=True, drop_last=True)\n",
        "VALID_LOADER = DataLoader(VALID_DATASET, batch_size=8, shuffle=False, drop_last=True)\n",
        "TEST_LOADER = DataLoader(TEST_DATASET, batch_size=8, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "YP5p5Nv1QTEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "\n",
        "# 이미지 크기를 줄이면서 ResNet 구조를 사용하기 위한 기본 모듈\n",
        "class Basic_ResNet_Downsample_Layer(nn.Module) :\n",
        "  def __init__(self, in_channels, out_channels) :\n",
        "    super().__init__()\n",
        "    \n",
        "    self.CONV_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 5), stride=(2, 1))\n",
        "    self.CONV_2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3), padding=1)\n",
        "\n",
        "    self.BN_1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.BN_2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "    self.LERU = nn.ReLU()\n",
        "\n",
        "    self.CONV_DOWN_SAMPLE = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 5), stride=(2, 1))\n",
        "\n",
        "    self.LAYER_SEQ = nn.Sequential(\n",
        "      self.CONV_1, self.BN_1, self.LERU,\n",
        "      self.CONV_2, self.BN_2\n",
        "    )\n",
        "  \n",
        "  def forward(self, x) :\n",
        "    x = self.LAYER_SEQ(x) + self.CONV_DOWN_SAMPLE(x)\n",
        "    x = self.LERU(x)\n",
        "    return x\n",
        "\n",
        "# 이미지 크기를 유지하면서 ResNet 구조를 사용하기 위한 기본 모듈\n",
        "class Basic_ResNet_Maintain_Layer(nn.Module) :\n",
        "  def __init__(self, in_channels, out_channels) :\n",
        "    super().__init__()\n",
        "    \n",
        "    self.CONV = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3), padding=1)\n",
        "    self.BN = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.LERU = nn.ReLU()\n",
        "\n",
        "    self.LAYER_SEQ = nn.Sequential(\n",
        "      self.CONV, self.BN, self.LERU\n",
        "    )\n",
        "  \n",
        "  def forward(self, x) :\n",
        "    return self.LAYER_SEQ(x) + x\n",
        "\n",
        "\n",
        "# 셀프 어텐션을 사용하는 Skip Layer 구조를 사용하기 위한 기본 모둘\n",
        "class Basic_Self_Attension_Skip_Layer(nn.Module) :\n",
        "  def __init__(self, input_size) :\n",
        "    super().__init__()\n",
        "\n",
        "    self.ATTENTION = torch.nn.MultiheadAttention(input_size, 8)\n",
        "    self.BN = nn.BatchNorm1d(num_features=8)\n",
        "  \n",
        "  def forward(self, x) :\n",
        "    x_ = x\n",
        "    x, _ = self.ATTENTION(x, x, x)\n",
        "    x = self.BN(x)\n",
        "    return x + x_\n",
        "\n",
        "\n",
        "# 기본 모듈을 겹겹히 조합하기 위한 주요 신경망 모듈\n",
        "class CRNN_Module(pl.LightningModule) :\n",
        "  def __init__(self, bow) :\n",
        "    super().__init__()\n",
        "    self.BOW = bow\n",
        "    self.REV_BOW = list(self.BOW.keys())\n",
        "\n",
        "    resnet_layers = []\n",
        "    resnet_layers.append(Basic_ResNet_Downsample_Layer(in_channels=3, out_channels=32))\n",
        "    for layer_index in range(1, 47+1) :\n",
        "      if layer_index%12 == 0 : resnet_layers.append(Basic_ResNet_Downsample_Layer(in_channels=32, out_channels=32))\n",
        "      else : resnet_layers.append(Basic_ResNet_Maintain_Layer(in_channels=32, out_channels=32))\n",
        "    resnet_layers.append(nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(2, 5)))\n",
        "    self.RESNET_LAYER_SEQ = nn.Sequential(*resnet_layers)\n",
        "\n",
        "\n",
        "    attenion_layers = [Basic_Self_Attension_Skip_Layer(32) for _ in range(5)]\n",
        "    self.SELF_ATTENSION_SKIP_LAYER_SEQ = nn.Sequential(*attenion_layers)\n",
        "\n",
        "\n",
        "    self.FC_1 = nn.Linear(32, 64)\n",
        "    self.FC_2 = nn.Linear(64, len(self.BOW))\n",
        "    self.LERU = nn.ReLU()\n",
        "\n",
        "    self.FC_LAYER_SEQ = nn.Sequential(\n",
        "        self.FC_1, self.LERU, self.FC_2\n",
        "    )\n",
        "  \n",
        "  def forward(self, x) :\n",
        "    x = self.RESNET_LAYER_SEQ(x)\n",
        "    x = x.view(x.shape[0], 32, -1)\n",
        "    x = x.permute(2, 0, 1)\n",
        "\n",
        "    x = self.SELF_ATTENSION_SKIP_LAYER_SEQ(x)\n",
        "    \n",
        "    x = self.FC_LAYER_SEQ(x)\n",
        "\n",
        "    x = F.log_softmax(x, dim=-1)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def training_step(self, batch, batch_idx) :\n",
        "    CTC_LOSS = self.__forward_To_CTC_Loss(batch)\n",
        "    self.log('train_ctc_loss', CTC_LOSS, on_epoch=True, prog_bar=True)\n",
        "    self.log('train_accuracy', self.__accuracy(batch), on_epoch=True, prog_bar=True)\n",
        "    return CTC_LOSS\n",
        "  \n",
        "  def validation_step(self, batch, batch_idx) :\n",
        "    self.log('valid_accuracy', self.__accuracy(batch), on_epoch=True, prog_bar=True)\n",
        "  \n",
        "  def test_step(self, batch, batch_idx) :\n",
        "    self.log('test_accuracy', self.__accuracy(batch), on_epoch=True, prog_bar=True)\n",
        "  \n",
        "  def predict_step(self, batch, batch_idx) :\n",
        "    X, Y = batch\n",
        "    return self.__pred_To_Letters(X)\n",
        "\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "      return Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "  # 주어진 배치에 대한 CTC 손실을 반환시킥 위해서\n",
        "  def __forward_To_CTC_Loss(self, batch) :\n",
        "    X, Y = batch\n",
        "    PREDS = self(X)\n",
        "\n",
        "    PREDS_SIZE = torch.IntTensor([PREDS.size(0)]*PREDS.size(1))\n",
        "    TARGET_SIZE = torch.IntTensor([len(y_each) for y_each in Y])\n",
        "\n",
        "    CTC_LOSS = nn.CTCLoss(blank=0)(PREDS, Y, PREDS_SIZE, TARGET_SIZE)\n",
        "    return CTC_LOSS\n",
        "  \n",
        "  # 주어진 배치에 대한 정확도를 반환시키기 위해서\n",
        "  def __accuracy(self, batch) :\n",
        "    X, Y = batch\n",
        "    Y_LETTERS = self.__y_To_Letters(Y)\n",
        "    PRED_LETTERS = self.__pred_To_Letters(X)\n",
        "\n",
        "    correct_count = 0\n",
        "    for pred_index in range(len(PRED_LETTERS)) :\n",
        "      if PRED_LETTERS[pred_index] == Y_LETTERS[pred_index] : correct_count += 1\n",
        "    \n",
        "    ACCURACY = correct_count/len(PRED_LETTERS)\n",
        "    return ACCURACY\n",
        "  \n",
        "  # 신경망에서 예측된 백터를 문자열들로 반환시키기 위해서\n",
        "  def __pred_To_Letters(self, x) :\n",
        "    PREDS = self(x).transpose(1,0)\n",
        "    PRED_ARGMAXS = torch.argmax(PREDS, dim=-1)\n",
        "\n",
        "    output_pred_letters = []\n",
        "    for pred_argmax in PRED_ARGMAXS :\n",
        "      PRED_ARGMAX_PROCESSED = self.__process_Model_Predict(pred_argmax)\n",
        "      PRED_LETTERS = self.__predict_To_Letters(PRED_ARGMAX_PROCESSED)\n",
        "      output_pred_letters.append(PRED_LETTERS)\n",
        "    return output_pred_letters\n",
        "\n",
        "  # CTC 손실로 중복 예측된 라벨들의 중복을 제거시키고 정제하기 위해서\n",
        "  def __process_Model_Predict(self, pred_argmax) :\n",
        "    pred_letters = []\n",
        "    prev_letter = pred_argmax[0].item()\n",
        "    if prev_letter != 0 : pred_letters.append(prev_letter)\n",
        "\n",
        "    for letter in pred_argmax :\n",
        "      if letter.item() != 0 and letter.item() != prev_letter :\n",
        "        pred_letters.append(letter.item())\n",
        "      prev_letter = letter.item()\n",
        "    return pred_letters\n",
        "  \n",
        "  # 예측된 코드를 문자열로 변환시키기 위해서\n",
        "  def __predict_To_Letters(self, pred) :\n",
        "    return \"\".join([self.REV_BOW[code] for code in pred])\n",
        "  \n",
        "  # 정답 백터를 문자열 리스트로 변환시키기 위해서\n",
        "  def __y_To_Letters(self, y) :\n",
        "    return [\"\".join([self.REV_BOW[code] for code in y_each]) for y_each in y]"
      ],
      "metadata": {
        "id": "PV8b9GmVQXKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# 신경망을 통해서 캡차 데이터를 일관성있게 예측하기 위해서\n",
        "class Predict_Captcha_Label :\n",
        "  def __init__(self, model_path, bow) :\n",
        "    self.MODEL = CRNN_Module.load_from_checkpoint(model_path, bow=bow)\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    self.TRAINER = pl.Trainer(accelerator=DEVICE, enable_progress_bar=False, logger=False)\n",
        "\n",
        "  def __preprocessing_Image(self, image) :\n",
        "    USER_IMAGE = Image.fromarray(np.uint8(image)).convert(\"L\").convert(\"RGB\")\n",
        "    USER_IMAGE = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "    ])(USER_IMAGE)\n",
        "    return USER_IMAGE\n",
        "\n",
        "  def __convert_Image_To_Data_Loader(self, images) :\n",
        "    user_images = list(map(self.__preprocessing_Image, images))\n",
        "    while len(user_images) != 8 :\n",
        "      user_images.append(user_images[0])\n",
        "    \n",
        "    USER_IMAGES = torch.stack(user_images)\n",
        "    USER_IMAGE_DATASET = TensorDataset(USER_IMAGES, torch.zeros(8))\n",
        "    USER_IMAGE_LOADER = DataLoader(USER_IMAGE_DATASET, batch_size=8)\n",
        "    return USER_IMAGE_LOADER\n",
        "  \n",
        "  # 단일 이미지에 대한 예측 결과를 반환시키기 위해서\n",
        "  def predict_Captcha_Label(self, image) :\n",
        "      DATA_LOADER = self.__convert_Image_To_Data_Loader([image])\n",
        "      PRED = self.TRAINER.predict(self.MODEL, dataloaders=DATA_LOADER)[0][0]\n",
        "      return PRED\n",
        "  \n",
        "  # 여러 이미지에 대한 예측 결과를 반환시키기 위해서\n",
        "  def predict_Captcha_Labels(self, images) :\n",
        "    DATA_LOADER = self.__convert_Image_To_Data_Loader(images)\n",
        "    PREDS = self.TRAINER.predict(self.MODEL, dataloaders=DATA_LOADER)[0][:len(images)]\n",
        "    return PREDS"
      ],
      "metadata": {
        "id": "dteQK7_JQdJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "\n",
        "# HTTP 요청에 대한 통합된 인터페이스를 제공하기 위한 라이브러리\n",
        "class Request :\n",
        "  # 자연스러운 요청을 위한 기반 헤더\n",
        "  GLOBAL_HEADERS = {\"Accept\" : \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
        "                    \"Accept-Encoding\" : \"gzip, deflate, br\",\n",
        "                    \"Accept-Language\" : \"ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
        "                    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"}\n",
        "\n",
        "  # HTTP GET 요청을 수행하고 응답을 받기 위해서\n",
        "  @staticmethod\n",
        "  def get(url, headers={}, cookies={}) :\n",
        "    headers.update(Request.GLOBAL_HEADERS)\n",
        "    return requests.get(url, headers=headers, cookies=cookies)\n",
        "  \n",
        "  # HTTP POST 요청을 수행해고 응답을 받기 위해서\n",
        "  @staticmethod\n",
        "  def post(url, headers={}, cookies={}, data={}) :\n",
        "    headers.update(Request.GLOBAL_HEADERS)\n",
        "    return requests.post(url, headers=headers, cookies=cookies, data=data)\n",
        "\n",
        "# DC 인사이드의 캡차 이미지를 얻기 위해서\n",
        "class Dcincide_Captcha_API :\n",
        "  def __init__(self) :\n",
        "    self.GALL_ID = \"lilyfever\"\n",
        "    self.KCAPTCHA_TYPE = \"recommend\"\n",
        "    self.GALL_TYPE = \"M\"\n",
        "\n",
        "    self.SESSION_COOKIES = Request.get(f\"https://gall.dcinside.com/mgallery/board/write/?id={self.GALL_ID}\").cookies\n",
        "    self.SESSION_COOKIE_INFO = {\"PHPSESSID\":self.SESSION_COOKIES[\"PHPSESSID\"], \"ci_c\":self.SESSION_COOKIES[\"ci_c\"]}\n",
        "    self._init_Captcha_Session()\n",
        "  \n",
        "  # 새로운 캡차 이미지를 얻기 위해서 캡차 세션을 초기화시킴\n",
        "  def _init_Captcha_Session(self) :\n",
        "    SESSION_HTTP_HEADER = {\"Content-Type\":\"application/x-www-form-urlencoded; charset=UTF-8\", \"X-Requested-With\":\"XMLHttpRequest\"}\n",
        "    SESSION_DATAS = {\"ci_t\":self.SESSION_COOKIES[\"ci_c\"], \"gall_id\":self.GALL_ID, \"kcaptcha_type\":self.KCAPTCHA_TYPE, \"_GALLTYPE_\":self.GALL_TYPE}\n",
        "    Request.post(\"https://gall.dcinside.com/kcaptcha/session\", SESSION_HTTP_HEADER, self.SESSION_COOKIE_INFO, SESSION_DATAS)\n",
        "\n",
        "  # 생성된 캡차 세션에 존재하는 캡차 이미지를 PIL 형태로 얻기 위해서\n",
        "  def _captcha_Image(self) :\n",
        "    IMG_RES = Request.get(f\"https://gall.dcinside.com/kcaptcha/image/?gall_id={self.GALL_ID}&kcaptcha_type={self.KCAPTCHA_TYPE}\", {}, self.SESSION_COOKIE_INFO)\n",
        "    return Image.open(BytesIO(IMG_RES.content))\n",
        "\n",
        "  # 새로운 캡차 문자열 이미지를 얻기 위해서\n",
        "  def new_Captcha_Image(self) :\n",
        "    self._init_Captcha_Session()\n",
        "    return self._captcha_Image()\n",
        "  \n",
        "  # 이전과 정답이 동일하면서 형태만 다른 캡차 문자열 이미지를 얻기 위해서\n",
        "  def same_Captcha_Image(self) :\n",
        "    return self._captcha_Image()\n",
        "\n",
        "# 파일시스템 관련 조작을 위해서\n",
        "class File_System :\n",
        "  # 디렉토리가 없을 경우 생성시키기 위해서\n",
        "  @staticmethod\n",
        "  def make_Directory_If_Not_Exist(dir_path) :\n",
        "    if not os.path.exists(dir_path) : os.mkdir(dir_path)\n",
        "  \n",
        "  # 디렉토리 내부의 파일 개수를 반환받기 위해서\n",
        "  @staticmethod\n",
        "  def count_Num_Of_Files(dir_path) :\n",
        "    return len(os.listdir(dir_path))\n",
        "\n",
        "  # 특정 디렉토리를 .zip 형태로 압축시키기 위해서\n",
        "  @staticmethod\n",
        "  def compress_With_Zip(dir_path, zip_name) :\n",
        "    os.system(f\"zip -r {zip_name} {dir_path}\")\n",
        "\n",
        "  # 특정 디렉토리를 완전하게 삭제시키기 위해서\n",
        "  @staticmethod\n",
        "  def remove_Directory(dir_path) :\n",
        "    os.system(f\"rm -r {dir_path}\")\n",
        "\n",
        "# 자료형변환을 간편하게 수행하기 위한 라이브러리\n",
        "class Convert :\n",
        "  # 넘파이 배열을 PIL 이미지 형태로 변환시키기 위해서\n",
        "  @staticmethod\n",
        "  def numpy_Array_To_PIL_Image(numpy_array, color_channel=\"RGB\") :\n",
        "    return Image.fromarray(np.uint8(numpy_array)).convert(color_channel)"
      ],
      "metadata": {
        "id": "2omFnq1RQdu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# 캡차 이미지를 자동으로 생성시키기 위해서\n",
        "IMAGE_DIRECTORY = \"./captchas\" # 출력시킬 캡차 폴더명\n",
        "File_System.make_Directory_If_Not_Exist(IMAGE_DIRECTORY)\n",
        "\n",
        "CAPTCHA_API = Dcincide_Captcha_API()\n",
        "PREDICT_CAPTCHA_LABEL = Predict_Captcha_Label(\"/content/Resnet_With_Attention_Complete_Train-0.9992_Valid-0.9841_Test-0.9870\", bow=TRAIN_DATASET.BOW)\n",
        "\n",
        "target_count = 10000 # 다운로드시킬 캡차 이미지의 총 개수\n",
        "while True :\n",
        "  captcha_images = []\n",
        "  save_image = None\n",
        "  while True :\n",
        "    try :\n",
        "      captcha_images = []\n",
        "      captcha_images.append(CAPTCHA_API.new_Captcha_Image())\n",
        "      captcha_images.append(CAPTCHA_API.same_Captcha_Image())\n",
        "      captcha_images.append(CAPTCHA_API.same_Captcha_Image())\n",
        "      save_image = CAPTCHA_API.same_Captcha_Image()\n",
        "      break\n",
        "    except :\n",
        "      time.sleep(3.0)\n",
        "      CAPTCHA_API = Dcincide_Captcha_API()\n",
        "  \n",
        "  TOTAL_FILE_COUNT = File_System.count_Num_Of_Files(IMAGE_DIRECTORY)\n",
        "  PRED_LABELS = PREDICT_CAPTCHA_LABEL.predict_Captcha_Labels(captcha_images)\n",
        "  if PRED_LABELS.count(PRED_LABELS[0]) == len(PRED_LABELS) :\n",
        "    IMAGE_FILE_PATH_TO_SAVE = f\"{IMAGE_DIRECTORY}/{PRED_LABELS[0]}.jpg\"\n",
        "    save_image.save(IMAGE_FILE_PATH_TO_SAVE)\n",
        "    print(f\"[*] 예측 일치로 인한 이미지 추가 ! : 파일 총 개수 - {TOTAL_FILE_COUNT+1}/{target_count} / 대상 이미지 위치 : {IMAGE_FILE_PATH_TO_SAVE}\")\n",
        "    if TOTAL_FILE_COUNT + 1 >= target_count : break\n",
        "    \n",
        "  else :\n",
        "    print(f\"[*] 예측 불일치로 이미지 추가 실패 ! : 파일 총 개수 - {TOTAL_FILE_COUNT}/{target_count}\")\n",
        "\n",
        "File_System.compress_With_Zip(IMAGE_DIRECTORY, \"./\" + IMAGE_DIRECTORY.split(\"/\")[-1] + \".zip\")\n",
        "print(\"[*] 캡차 자동 추가 시스템 작동 완료 !\")"
      ],
      "metadata": {
        "id": "BOShJfE7QkUI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}